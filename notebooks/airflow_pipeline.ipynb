{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Airflow DAG definition for data pipeline\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.operators.python_operator import PythonOperator\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    'owner': 'airflow',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2023, 1, 1),\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'data_pipeline',\n",
    "    default_args=default_args,\n",
    "    description='A simple data pipeline',\n",
    "    schedule_interval=timedelta(days=1),\n",
    ")\n",
    "\n",
    "csv_file = 'example.csv'\n",
    "json_file = 'example.json'\n",
    "parquet_file_csv = 'example_csv.parquet'\n",
    "parquet_file_json = 'example_json.parquet'\n",
    "avro_file_csv = 'example_csv.avro'\n",
    "avro_file_json = 'example_json.avro'\n",
    "db_uri = 'postgresql://user:password@localhost:5432/mydatabase'\n",
    "table_name_csv = 'csv_table'\n",
    "table_name_json = 'json_table'\n",
    "\n",
    "convert_csv_to_parquet = PythonOperator(\n",
    "    task_id='convert_csv_to_parquet',\n",
    "    python_callable=csv_to_parquet,\n",
    "    op_kwargs={'csv_file': csv_file, 'parquet_file': parquet_file_csv},\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "convert_json_to_parquet = PythonOperator(\n",
    "    task_id='convert_json_to_parquet',\n",
    "    python_callable=json_to_parquet,\n",
    "    op_kwargs={'json_file': json_file, 'parquet_file': parquet_file_json},\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "convert_csv_to_avro = PythonOperator(\n",
    "    task_id='convert_csv_to_avro',\n",
    "    python_callable=csv_to_avro,\n",
    "    op_kwargs={'csv_file': csv_file, 'avro_file': avro_file_csv, 'schema': schema},\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "convert_json_to_avro = PythonOperator(\n",
    "    task_id='convert_json_to_avro',\n",
    "    python_callable=json_to_avro,\n",
    "    op_kwargs={'json_file': json_file, 'avro_file': avro_file_json, 'schema': schema},\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "save_parquet_csv_to_db = PythonOperator(\n",
    "    task_id='save_parquet_csv_to_db',\n",
    "    python_callable=save_parquet_to_db,\n",
    "    op_kwargs={'parquet_file': parquet_file_csv, 'db_uri': db_uri, 'table_name': table_name_csv},\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "save_parquet_json_to_db = PythonOperator(\n",
    "    task_id='save_parquet_json_to_db',\n",
    "    python_callable=save_parquet_to_db,\n",
    "    op_kwargs={'parquet_file': parquet_file_json, 'db_uri': db_uri, 'table_name': table_name_json},\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "save_avro_csv_to_db = PythonOperator(\n",
    "    task_id='save_avro_csv_to_db',\n",
    "    python_callable=save_avro_to_db,\n",
    "    op_kwargs={'avro_file': avro_file_csv, 'db_uri': db_uri, 'table_name': table_name_csv, 'schema': schema},\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "save_avro_json_to_db = PythonOperator(\n",
    "    task_id='save_avro_json_to_db',\n",
    "    python_callable=save_avro_to_db,\n",
    "    op_kwargs={'avro_file': avro_file_json, 'db_uri': db_uri, 'table_name': table_name_json, 'schema': schema},\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "(convert_csv_to_parquet >> save_parquet_csv_to_db)\n",
    "(convert_json_to_parquet >> save_parquet_json_to_db)\n",
    "(convert_csv_to_avro >> save_avro_csv_to_db)\n",
    "(convert_json_to_avro >> save_avro_json_to_db)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
